{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import urllib.request, json \n",
    "import string, re\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "with open('API_key.txt', 'r') as file:\n",
    "    openai.api_key = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/bamboogle.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(str(s)))))\n",
    "\n",
    "def extract_answer(generated):\n",
    "    if '\\n' not in generated:\n",
    "        last_line =  generated\n",
    "    else: \n",
    "        last_line = generated.split('\\n')[-1]\n",
    "\n",
    "    if ':' not in last_line:\n",
    "        after_colon = last_line\n",
    "    else:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "    after_colon = after_colon.strip()\n",
    "    if not after_colon.strip():\n",
    "        return \"\"\n",
    "    return normalize_answer(after_colon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\n\"\n",
    "system_prompt = f\"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-04-21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_is_right_EM(prediction, real_answers):\n",
    "    # might be multiple acceptable answers (this appears rare from my initial scan)\n",
    "    assert type(real_answers) == list\n",
    "    # should be cleaned already, do it again just in case\n",
    "    clean_pred = normalize_answer(prediction)\n",
    "    is_right = False\n",
    "    for potential_answer in real_answers:\n",
    "        potential_answer_clean = normalize_answer(potential_answer)\n",
    "        if clean_pred == potential_answer_clean:\n",
    "            is_right = True\n",
    "    return is_right\n",
    "\n",
    "def compute_is_right_cover_EM(prediction, real_answers):\n",
    "    # might be multiple acceptable answers (this appears rare from my initial scan)\n",
    "    assert type(real_answers) == list\n",
    "    # should be cleaned already, do it again just in case\n",
    "    clean_pred = normalize_answer(prediction)\n",
    "    is_right = False\n",
    "    for potential_answer in real_answers:\n",
    "        potential_answer_clean = normalize_answer(potential_answer)\n",
    "        if potential_answer_clean in clean_pred:\n",
    "            is_right = True\n",
    "\n",
    "    return is_right\n",
    "\n",
    "# def compute_is_right_GPT_opinion(question, prediction, real_answers):\n",
    "# #     prompt = f\"\"\"Your task is to compare a language model's response to a question with one or more acceptable ground truth answers to said question.\n",
    "# # VERY IMPORTANT: Numerical or ID-code answers MUST MATCH EXACTLY (up to differences in units). For other response types you should interpet responses for semantic similarity to ground truth.\"\"\"\n",
    "# #     prompt += f\"Here is the question that was asked: \\\"{question}\\\"\\n\"\n",
    "# #     prompt += f\"Here are the acceptable answer(s) for this question: [\\\"{real_answers[0]}\\\"\"\n",
    "# #     for answer in real_answers[1:]:\n",
    "# #         prompt += f\", \\\"{answer}\\\"\"\n",
    "# #     prompt += \"]\\n\"\n",
    "# #     prompt += f\"Here is the response of the model which you to are to evaluate: \\\"{prediction}\\\"\\n\"\n",
    "# #     prompt += \"\"\"Respond \\\"CORRECT\\\" if the model's response matches one of the ground truths and \\\"INCORRECT\\\" otherwise.\n",
    "# # If the model disagrees with the premise of the question or claims there's no answer, you should consider it to be INCORRECT.\n",
    "# # You should include reasoning in your response, and your response must include \\\"CORRECT\\\" or \\\"INCORRECT\\\".\n",
    "# # VERY IMPORTANT: You MUST IGNORE your own opinion on the question's validity or its answer. ONLY COMPARE THE MODEL'S RESPONSE WITH THE GIVEN GROUND TRUTHS.\"\"\"\n",
    "\n",
    "#     prompt = f\"\"\"Your task is to determine whether a language model has gotten the correct answer to a question. You should only consider responses to be correct\n",
    "#     if they include the ground truth answer exactly, but it doesn't have to be a perfect substring match or perfect spelling as long as the response\n",
    "#     is clearly referring to the same thing as the ground truth answer.\"\"\"\n",
    "#     # prompt += f\"Here is the question that was asked: \\\"{question}\\\"\\n\"\n",
    "#     prompt += f\"Here is the ground truth answer(s) for this question: [\\\"{real_answers[0]}\\\"\"\n",
    "#     for answer in real_answers[1:]:\n",
    "#         prompt += f\", \\\"{answer}\\\"\"\n",
    "#     prompt += \"]\\n\"\n",
    "#     prompt += f\"Here is the response of the model which you to are to evaluate: \\\"{prediction}\\\"\\n\"\n",
    "#     prompt += \"\"\"Respond \\\"CORRECT\\\" if the model's response matches one of the ground truths and \\\"INCORRECT\\\" otherwise.\"\"\"\n",
    "#     # print(prompt)\n",
    "#     # print(prompt)\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         max_tokens=200,\n",
    "#         stop='\\n\\n',\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": system_prompt},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         temperature=0\n",
    "#     )\n",
    "    \n",
    "#     return \"INCORRECT\" not in response['choices'][0][\"message\"][\"content\"]\n",
    "\n",
    "def DA_compute_is_right_GPT_opinion(question, prediction, real_answers):\n",
    "    prompt = f\"\"\"Your task is to determine whether a language model has gotten the correct answer to a question. You should only consider responses to be correct if they are roughly of the form \\\"the final answer is: <answer>\\\" or just \\\"<answer>\\\" without any other text or reasoning and <answer> matches the ground truth answer.\n",
    "    Note that the answer needn't have the same spelling and formatting as the ground truth to be correct long as as long as they're clearly referring to the same thing, but if the response contains ANYTHING else, such as reasoning or explanation, it should be considered incorrect because we explicitly told the model not to include explanation.\"\"\"\n",
    "    # prompt += f\"Here is the question that was asked: \\\"{question}\\\"\\n\"\n",
    "    prompt += f\"Here is the ground truth answer(s) for this question: [\\\"{real_answers[0]}\\\"\"\n",
    "    for answer in real_answers[1:]:\n",
    "        prompt += f\", \\\"{answer}\\\"\"\n",
    "    prompt += \"]\\n\"\n",
    "    prompt += f\"Here is the response of the model which you to are to evaluate: \\\"{prediction}\\\"\\n\"\n",
    "    prompt += \"\"\"Respond \\\"CORRECT\\\" if the model's response matches the ground truth according to the metric I've outlined and \\\"INCORRECT\\\" otherwise.\"\"\"\n",
    "    # print(prompt)\n",
    "    # print(prompt)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=200,\n",
    "        stop='\\n\\n',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return \"INCORRECT\" not in response['choices'][0][\"message\"][\"content\"]\n",
    "\n",
    "def COT_compute_is_right_GPT_opinion(question, prediction, real_answers):\n",
    "    prompt = f\"\"\"Your task is to determine whether a language model has gotten the correct answer to a question. You should only consider responses to be correct\n",
    "    if they include the ground truth answer exactly, but it doesn't have to be a perfect substring match or perfect spelling as long as the response\n",
    "    is clearly referring to the same thing as the ground truth answer. It is acceptable (and expected) for the response to contain other text such as reasoning.\"\"\"\n",
    "    # prompt += f\"Here is the question that was asked: \\\"{question}\\\"\\n\"\n",
    "    prompt += f\"Here is the ground truth answer(s) for this question: [\\\"{real_answers[0]}\\\"\"\n",
    "    for answer in real_answers[1:]:\n",
    "        prompt += f\", \\\"{answer}\\\"\"\n",
    "    prompt += \"]\\n\"\n",
    "    prompt += f\"Here is the response of the model which you to are to evaluate: \\\"{prediction}\\\"\\n\"\n",
    "    prompt += \"\"\"Respond \\\"CORRECT\\\" if the model's response matches the ground truth according to the metric I've outlined and \\\"INCORRECT\\\" otherwise.\"\"\"\n",
    "    # print(prompt)\n",
    "    # print(prompt)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=200,\n",
    "        stop='\\n\\n',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return \"INCORRECT\" not in response['choices'][0][\"message\"][\"content\"]\n",
    "\n",
    "def SA_compute_is_right_GPT_opinion(question, prediction, real_answers):\n",
    "    prompt = f\"\"\"Your task is to determine whether a language model has gotten the correct answer to a question. You should only consider responses to be correct\n",
    "    if they include the ground truth answer exactly, but it doesn't have to be a perfect substring match or perfect spelling as long as the response\n",
    "    is clearly referring to the same thing as the ground truth answer. It is acceptable (and expected) for the response to contain other text, likely\n",
    "    a series of subquestions and their answers that assist in answering the original question.\"\"\"\n",
    "    # prompt += f\"Here is the question that was asked: \\\"{question}\\\"\\n\"\n",
    "    prompt += f\"Here is the ground truth answer(s) for this question: [\\\"{real_answers[0]}\\\"\"\n",
    "    for answer in real_answers[1:]:\n",
    "        prompt += f\", \\\"{answer}\\\"\"\n",
    "    prompt += \"]\\n\"\n",
    "    prompt += f\"Here is the response of the model which you to are to evaluate: \\\"{prediction}\\\"\\n\"\n",
    "    prompt += \"\"\"Respond \\\"CORRECT\\\" if the model's response matches the ground truth according to the metric I've outlined and \\\"INCORRECT\\\" otherwise.\"\"\"\n",
    "    # print(prompt)\n",
    "    # print(prompt)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        max_tokens=200,\n",
    "        stop='\\n\\n',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    return \"INCORRECT\" not in response['choices'][0][\"message\"][\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LM_full_question(prompt, sample, current_model, compute_is_right_GPT_opinion, extraction=extract_answer, max_tokens=450, start='Answer:'):\n",
    "    question = sample['Question']\n",
    "    cur_prompt = prompt_prefix + prompt + '\\n' + '\\n' + 'Question: ' + question + '\\n' + start\n",
    "    # cur_prompt = prompt + '\\n' + '\\n' + 'Question: ' + question + '\\n' + start\n",
    "\n",
    "    if current_model in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "        ans = openai.ChatCompletion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            stop='\\n\\n',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": cur_prompt}\n",
    "            ]\n",
    "        )\n",
    "        response_text = ans['choices'][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        ans = openai.Completion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            stop='\\n\\n',\n",
    "            prompt=cur_prompt,\n",
    "            temperature=0\n",
    "        )\n",
    "        response_text = ans['choices'][0]['text']\n",
    "    failure_response = {\n",
    "        \"question\": sample['Question'],\n",
    "        \"prompt\": cur_prompt,\n",
    "        \"answer\": sample['Answer'],\n",
    "        \"returned\": response_text,\n",
    "        \"is_right_EM\": False,\n",
    "        \"is_right_CEM\": False,\n",
    "        \"is_right_GPT_opinion\": False\n",
    "    }\n",
    "    if response_text.strip() == '':\n",
    "        return failure_response\n",
    "    # print(\"not empty: \" + response_text.strip())\n",
    "    clean_ans = extraction(response_text)\n",
    "    # print(\"clean answer: \" + clean_ans)\n",
    "    if clean_ans.strip() == '':\n",
    "        return failure_response\n",
    "    is_right_EM = compute_is_right_EM(clean_ans, [sample['Answer']])\n",
    "    is_right_CEM = compute_is_right_cover_EM(response_text, [sample['Answer']])\n",
    "    is_right_GPT_opinion = compute_is_right_GPT_opinion(question, response_text, [sample['Answer']])\n",
    "    jsonres = {\n",
    "        \"question\": sample['Question'],\n",
    "        \"prompt\": cur_prompt,\n",
    "        \"answer\": sample['Answer'],\n",
    "        \"returned\": response_text,\n",
    "        \"is_right_EM\": is_right_EM,\n",
    "        \"is_right_CEM\": is_right_CEM,\n",
    "        \"is_right_GPT_opinion\": is_right_GPT_opinion\n",
    "    }\n",
    "    return jsonres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LM_subquestions(prompt_1, prompt_2, sample, current_model, compute_is_right_GPT_opinion, extraction=extract_answer, max_tokens=250, start='Answer:'):\n",
    "    prompt1_with_q = prompt_1 + '\\n' + '\\n' + 'Question: ' + sample['Q1'] + '\\n' + start\n",
    "    prompt2_with_q = prompt_2 + '\\n' + '\\n' + 'Question: ' + sample['Q2'] + '\\n' + start\n",
    "\n",
    "\n",
    "    prompt1_with_q = prompt_prefix + prompt_1 + '\\n' + '\\n' + 'Question: ' + sample['Q1'] + '\\n' + start\n",
    "    prompt2_with_q = prompt_prefix + prompt_2 + '\\n' + '\\n' + 'Question: ' + sample['Q2'] + '\\n' + start\n",
    "\n",
    "    if current_model in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "        q1_response = openai.ChatCompletion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            stop=\"\\n\\n\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt1_with_q}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        ans1 = q1_response['choices'][0][\"message\"][\"content\"]\n",
    "        \n",
    "        q2_response = openai.ChatCompletion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            stop=\"\\n\\n\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":  system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt2_with_q}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        ans2 = q2_response['choices'][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        q1_response = openai.Completion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            stop=\"\\n\\n\",\n",
    "            prompt=prompt1_with_q,\n",
    "            temperature=0\n",
    "        )\n",
    "        ans1 = q1_response['choices'][0]['text']\n",
    "\n",
    "        q2_response = openai.Completion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            stop=\"\\n\\n\",\n",
    "            prompt=prompt2_with_q,\n",
    "            temperature=0\n",
    "        )\n",
    "        ans2 = q2_response['choices'][0]['text']\n",
    "\n",
    "    q1_clean_ans = extraction(ans1)\n",
    "    q1_is_right_EM = compute_is_right_EM(q1_clean_ans, sample['A1'])\n",
    "    q1_is_right_CEM = compute_is_right_cover_EM(ans1, sample['A1'])\n",
    "    q1_is_right_GPT_opinion = compute_is_right_GPT_opinion(sample[\"Q1\"], ans1, [sample['A1']])\n",
    "\n",
    "\n",
    "    q2_clean_ans = extraction(ans2)\n",
    "    q2_is_right_EM = compute_is_right_EM(q2_clean_ans, sample['A2'])\n",
    "    q2_is_right_CEM = compute_is_right_cover_EM(ans2, sample['A2'])\n",
    "    q2_is_right_GPT_opinion = compute_is_right_GPT_opinion(sample[\"Q2\"], ans2, [sample['A2']])\n",
    "\n",
    "\n",
    "    jsonres = {\n",
    "        \"Q1\": sample['Q1'],\n",
    "        \"Q1_gt\": sample['A1'],\n",
    "        \"Q1_pred\": q1_clean_ans,\n",
    "        \"Q1_is_right_EM\": q1_is_right_EM,\n",
    "        \"Q1_is_right_CEM\": q1_is_right_CEM,\n",
    "        \"Q1_is_right_GPT_opinion\": q1_is_right_GPT_opinion,\n",
    "        \"Q2\": sample['Q2'],\n",
    "        \"Q2_gt\": sample['A2'],\n",
    "        \"Q2_pred\": q2_clean_ans,\n",
    "        \"Q2_is_right_EM\": q2_is_right_EM,\n",
    "        \"Q2_is_right_CEM\": q2_is_right_CEM,\n",
    "        \"Q2_is_right_GPT_opinion\": q2_is_right_GPT_opinion,\n",
    "        \"Q1_and_Q2_right_EM\": q1_is_right_EM and q2_is_right_EM,\n",
    "        \"Q1_and_Q2_right_CEM\": q1_is_right_CEM and q2_is_right_CEM,\n",
    "        \"Q1_and_Q2_right_GPT_opinion\":  q2_is_right_GPT_opinion and q2_is_right_GPT_opinion,\n",
    "        \"Q1_prompt\": prompt1_with_q,\n",
    "        \"Q2_prompt\": prompt2_with_q,\n",
    "        'Q1_returned': ans1,\n",
    "        'Q2_returned': ans2\n",
    "    }\n",
    "\n",
    "    return jsonres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_results_dict(results, subquestions_result, direct_answer_result, chain_of_thought_result, self_ask_result):\n",
    "    metrics = [\"EM\", \"CEM\", \"GPT_opinion\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "        if subquestions_result[f\"Q1_and_Q2_right_{metric}\"]:\n",
    "            results[\"summary\"][f\"both_subquestions_correct_{metric}\"] += 1\n",
    "\n",
    "            if not direct_answer_result[f\"is_right_{metric}\"]:\n",
    "                results[\"summary\"][f\"full_question_direct_answer_wrong_when_subquestions_correct_{metric}\"] += 1\n",
    "\n",
    "            if not chain_of_thought_result[f\"is_right_{metric}\"]:\n",
    "                results[\"summary\"][f\"full_question_chain_of_thought_wrong_when_subquestions_correct_{metric}\"] += 1\n",
    "\n",
    "            if not self_ask_result[f\"is_right_{metric}\"]:\n",
    "                results[\"summary\"][f\"full_question_self_ask_wrong_when_subquestions_correct_{metric}\"] += 1\n",
    "\n",
    "        if direct_answer_result[f\"is_right_{metric}\"]:\n",
    "            results[\"summary\"][f\"full_question_direct_answer_correct_{metric}\"] += 1\n",
    "            if not subquestions_result[f\"Q1_and_Q2_right_{metric}\"]:\n",
    "                results[\"summary\"][f\"subquestions_wrong_when_full_question_direct_answer_correct_{metric}\"] += 1\n",
    "\n",
    "        if chain_of_thought_result[f\"is_right_{metric}\"]:\n",
    "            results[\"summary\"][f\"full_question_chain_of_thought_correct_{metric}\"] += 1\n",
    "            if not subquestions_result[f\"Q1_and_Q2_right_{metric}\"]:\n",
    "                results[\"summary\"][f\"subquestions_wrong_when_full_question_chain_of_thought_correct_{metric}\"] += 1\n",
    "\n",
    "        if self_ask_result[f\"is_right_{metric}\"]:\n",
    "            results[\"summary\"][f\"full_question_self_ask_correct_{metric}\"] += 1\n",
    "            if not subquestions_result[f\"Q1_and_Q2_right_{metric}\"]:\n",
    "                results[\"summary\"][f\"subquestions_wrong_when_full_question_self_ask_correct_{metric}\"] += 1\n",
    "\n",
    "    results[\"per_question_results\"].append({\n",
    "        \"subquestions_result\": subquestions_result,\n",
    "        \"direct_answer_result\": direct_answer_result,\n",
    "        \"chain_of_thought_result\": chain_of_thought_result,\n",
    "        \"self_ask_result\": self_ask_result\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the combined dictionary from the JSON file\n",
    "with open(\"data/bamboogle_prompts.json\", \"r\") as json_file:\n",
    "    all_prompts = json.load(json_file)\n",
    "\n",
    "# Extract the individual dictionaries\n",
    "chain_of_thought_prompt = all_prompts[\"chain_of_thought_prompt\"]\n",
    "self_ask_prompt = all_prompts[\"self_ask_prompt\"]\n",
    "direct_answer_prompt = all_prompts[\"direct_answer_prompt\"]\n",
    "subquestions_prompt = all_prompts[\"subquestions_prompt\"]\n",
    "# subquestion_1_prompt_dict = all_prompts[\"subquestion_1_prompt_dict\"]\n",
    "# subquestion_2_prompt_dict = all_prompts[\"subquestion_2_prompt_dict\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "results = {\n",
    "    \"per_question_results\": [],\n",
    "    \"summary\": {\n",
    "        \"full_question_direct_answer_correct_EM\": 0,\n",
    "        \"full_question_direct_answer_correct_CEM\": 0,\n",
    "        \"full_question_direct_answer_correct_GPT_opinion\": 0,\n",
    "        \"full_question_direct_answer_correct_human_opinion\": 0,\n",
    "        \"full_question_chain_of_thought_correct_EM\": 0,\n",
    "        \"full_question_chain_of_thought_correct_CEM\": 0,\n",
    "        \"full_question_chain_of_thought_correct_GPT_opinion\": 0,\n",
    "        \"full_question_chain_of_thought_correct_human_opinion\": 0,\n",
    "        \"full_question_self_ask_correct_EM\": 0,\n",
    "        \"full_question_self_ask_correct_CEM\": 0,\n",
    "        \"full_question_self_ask_correct_GPT_opinion\": 0,\n",
    "        \"full_question_self_ask_correct_human_opinion\": 0,\n",
    "        \"both_subquestions_correct_EM\": 0,\n",
    "        \"both_subquestions_correct_CEM\": 0,\n",
    "        \"both_subquestions_correct_GPT_opinion\": 0,\n",
    "        \"both_subquestions_correct_human_opinion\": 0,\n",
    "        \"subquestions_wrong_when_full_question_direct_answer_correct_EM\": 0,\n",
    "        \"subquestions_wrong_when_full_question_direct_answer_correct_CEM\": 0,\n",
    "        \"subquestions_wrong_when_full_question_direct_answer_correct_GPT_opinion\": 0,\n",
    "        \"subquestions_wrong_when_full_question_direct_answer_correct_human_opinion\": 0,\n",
    "        \"subquestions_wrong_when_full_question_chain_of_thought_correct_EM\": 0,\n",
    "        \"subquestions_wrong_when_full_question_chain_of_thought_correct_CEM\": 0,\n",
    "        \"subquestions_wrong_when_full_question_chain_of_thought_correct_GPT_opinion\": 0,\n",
    "        \"subquestions_wrong_when_full_question_chain_of_thought_correct_human_opinion\": 0,\n",
    "        \"subquestions_wrong_when_full_question_self_ask_correct_EM\": 0,\n",
    "        \"subquestions_wrong_when_full_question_self_ask_correct_CEM\": 0,\n",
    "        \"subquestions_wrong_when_full_question_self_ask_correct_GPT_opinion\": 0,\n",
    "        \"subquestions_wrong_when_full_question_self_ask_correct_human_opinion\": 0,\n",
    "        \"full_question_direct_answer_wrong_when_subquestions_correct_EM\": 0,\n",
    "        \"full_question_direct_answer_wrong_when_subquestions_correct_CEM\": 0,\n",
    "        \"full_question_direct_answer_wrong_when_subquestions_correct_GPT_opinion\": 0,\n",
    "        \"full_question_direct_answer_wrong_when_subquestions_correct_human_opinion\": 0,\n",
    "        \"full_question_chain_of_thought_wrong_when_subquestions_correct_EM\": 0,\n",
    "        \"full_question_chain_of_thought_wrong_when_subquestions_correct_CEM\": 0,\n",
    "        \"full_question_chain_of_thought_wrong_when_subquestions_correct_GPT_opinion\": 0,\n",
    "        \"full_question_chain_of_thought_wrong_when_subquestions_correct_human_opinion\": 0,\n",
    "        \"full_question_self_ask_wrong_when_subquestions_correct_EM\": 0,\n",
    "        \"full_question_self_ask_wrong_when_subquestions_correct_CEM\": 0,\n",
    "        \"full_question_self_ask_wrong_when_subquestions_correct_GPT_opinion\": 0,\n",
    "        \"full_question_self_ask_wrong_when_subquestions_correct_human_opinion\": 0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "error:  The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_419/793832120.py\", line 33, in <module>\n",
      "    self_ask_result = run_LM_full_question(self_ask_prompt, dp, model, SA_compute_is_right_GPT_opinion, start='Are follow up questions needed here: Yes.\\n')\n",
      "  File \"/tmp/ipykernel_419/3102365094.py\", line 44, in run_LM_full_question\n",
      "    is_right_GPT_opinion = compute_is_right_GPT_opinion(question, response_text, [sample['Answer']])\n",
      "  File \"/tmp/ipykernel_419/1928888727.py\", line 130, in SA_compute_is_right_GPT_opinion\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "error:  Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 24 Apr 2023 03:32:47 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7bcb47eb2c096826-SEA'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_419/793832120.py\", line 40, in <module>\n",
      "    subquestions_result = run_LM_subquestions(subquestion_1_prompt, subquestion_2_prompt, dp, model, DA_compute_is_right_GPT_opinion, extraction=extract_answer)\n",
      "  File \"/tmp/ipykernel_419/1857054115.py\", line 55, in run_LM_subquestions\n",
      "    q1_is_right_GPT_opinion = compute_is_right_GPT_opinion(sample[\"Q1\"], ans1, [sample['A1']])\n",
      "  File \"/tmp/ipykernel_419/1928888727.py\", line 77, in DA_compute_is_right_GPT_opinion\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 24 Apr 2023 03:32:47 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7bcb47eb2c096826-SEA'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 24 Apr 2023 03:32:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7bcb48030f786826-SEA'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_419/793832120.py\", line 10, in <module>\n",
      "    direct_answer_result = run_LM_full_question(direct_answer_prompt, dp, model, DA_compute_is_right_GPT_opinion)\n",
      "  File \"/tmp/ipykernel_419/3102365094.py\", line 44, in run_LM_full_question\n",
      "    is_right_GPT_opinion = compute_is_right_GPT_opinion(question, response_text, [sample['Answer']])\n",
      "  File \"/tmp/ipykernel_419/1928888727.py\", line 77, in DA_compute_is_right_GPT_opinion\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Mon, 24 Apr 2023 03:32:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7bcb48030f786826-SEA'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "error:  The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_419/793832120.py\", line 33, in <module>\n",
      "    self_ask_result = run_LM_full_question(self_ask_prompt, dp, model, SA_compute_is_right_GPT_opinion, start='Are follow up questions needed here: Yes.\\n')\n",
      "  File \"/tmp/ipykernel_419/3102365094.py\", line 44, in run_LM_full_question\n",
      "    is_right_GPT_opinion = compute_is_right_GPT_opinion(question, response_text, [sample['Answer']])\n",
      "  File \"/tmp/ipykernel_419/1928888727.py\", line 130, in SA_compute_is_right_GPT_opinion\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "error:  The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_419/793832120.py\", line 33, in <module>\n",
      "    self_ask_result = run_LM_full_question(self_ask_prompt, dp, model, SA_compute_is_right_GPT_opinion, start='Are follow up questions needed here: Yes.\\n')\n",
      "  File \"/tmp/ipykernel_419/3102365094.py\", line 44, in run_LM_full_question\n",
      "    is_right_GPT_opinion = compute_is_right_GPT_opinion(question, response_text, [sample['Answer']])\n",
      "  File \"/tmp/ipykernel_419/1928888727.py\", line 130, in SA_compute_is_right_GPT_opinion\n",
      "    response = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "error:  Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 421, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 416, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.9/ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.9/ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 400, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/six.py\", line 719, in reraise\n",
      "    raise value\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 423, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 330, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 516, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 529, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_419/793832120.py\", line 33, in <module>\n",
      "    self_ask_result = run_LM_full_question(self_ask_prompt, dp, model, SA_compute_is_right_GPT_opinion, start='Are follow up questions needed here: Yes.\\n')\n",
      "  File \"/tmp/ipykernel_419/3102365094.py\", line 7, in run_LM_full_question\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 216, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 527, in request_raw\n",
      "    raise error.Timeout(\"Request timed out: {}\".format(e)) from e\n",
      "openai.error.Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "while i < len(data):\n",
    "    dp = data[i]\n",
    "    # print(dp)\n",
    "    try:\n",
    "        # category = dp['category']\n",
    "\n",
    "        # Direct answer\n",
    "        direct_answer_prompt = direct_answer_prompt\n",
    "        direct_answer_result = run_LM_full_question(direct_answer_prompt, dp, model, DA_compute_is_right_GPT_opinion)\n",
    "        # if (not direct_answer_result[\"is_right_CEM\"] and \"INCORRECT\" not in direct_answer_result[\"is_right_GPT_opinion\"]) \\\n",
    "        #     or (direct_answer_result[\"is_right_CEM\"] and \"INCORRECT\" in direct_answer_result[\"is_right_GPT_opinion\"]):\n",
    "        #     for key in direct_answer_result.keys():\n",
    "        #         print(f\"{key}: {direct_answer_result[key]}\")\n",
    "\n",
    "        # for key in direct_answer_result.keys():\n",
    "        #     print(f\"{key}: {direct_answer_result[key]}\")\n",
    "\n",
    "\n",
    "        # Chain of thought\n",
    "        chain_of_thought_prompt = chain_of_thought_prompt\n",
    "        chain_of_thought_result = run_LM_full_question(chain_of_thought_prompt, dp, model, COT_compute_is_right_GPT_opinion)\n",
    "        # if (not chain_of_thought_result[\"is_right_CEM\"] and \"INCORRECT\" not in chain_of_thought_result[\"is_right_GPT_opinion\"]) or \\\n",
    "        #     (chain_of_thought_result[\"is_right_CEM\"] and \"INCORRECT\" in chain_of_thought_result[\"is_right_GPT_opinion\"]):\n",
    "        #     for key in chain_of_thought_result.keys():\n",
    "        #         print(f\"{key}: {chain_of_thought_result[key]}\")\n",
    "        # for key in chain_of_thought_result.keys():\n",
    "        #     print(f\"{key}: {chain_of_thought_result[key]}\")\n",
    "        # print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "        # Self-ask\n",
    "        self_ask_prompt = self_ask_prompt\n",
    "        self_ask_result = run_LM_full_question(self_ask_prompt, dp, model, SA_compute_is_right_GPT_opinion, start='Are follow up questions needed here: Yes.\\n')\n",
    "        # print(self_ask_result[\"Prediction\"])\n",
    "        # print(self_ask_result[\"Answer\"])\n",
    "\n",
    "        # Subquestions\n",
    "        subquestion_1_prompt = subquestions_prompt\n",
    "        subquestion_2_prompt = subquestions_prompt\n",
    "        subquestions_result = run_LM_subquestions(subquestion_1_prompt, subquestion_2_prompt, dp, model, DA_compute_is_right_GPT_opinion, extraction=extract_answer)\n",
    "        update_results_dict(results, subquestions_result, direct_answer_result, chain_of_thought_result, self_ask_result)\n",
    "        print(i)\n",
    "        i += 1\n",
    "    except Exception as e:\n",
    "        print(\"error: \", e)\n",
    "        traceback.print_exc()\n",
    "\n",
    "with open(f'results/Bamboogle_results_{model}_prefixed.json', 'w') as outfile:\n",
    "    json.dump(results, outfile, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    with open(f'results/Bamboogle_results_{model}_prefixed.json', 'w') as outfile:\n",
    "        json.dump(results, outfile, ensure_ascii=False, indent=4)\n",
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['per_question_results', 'summary'])\n"
     ]
    }
   ],
   "source": [
    "with open(f'results/Bamboogle_results_{model}.json', 'r') as infile:\n",
    "    # json.dump(results, outfile, ensure_ascii=False, indent=4)\n",
    "    results = json.load(infile)\n",
    "print(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Can people who have celiac eat camel meat?\n",
      "DA: Yes, people with celiac disease can eat camel meat as it does not contain gluten, which is the protein that they need to avoid. However, it's important to make sure the meat is not contaminated during preparation or cooking processes. As with any dietary restrictions or concerns, it's always best to consult a doctor or a registered dietitian.\n",
      "COT: There is not enough information to provide a definitive answer. However, if camel meat has not been processed with gluten-containing ingredients or contaminated with gluten during preparation, it is possible that people with celiac disease can safely eat camel meat. Nonetheless, it is advisable for individuals with celiac disease to consult with a healthcare professional or a registered dietitian before consuming any food if they are unsure about its gluten content.\n",
      "SA: Follow up: Can camel meat contain gluten?\n",
      "Intermediate answer: It is possible for camel meat to be contaminated with gluten if it is processed or cooked with ingredients that contain gluten.\n",
      "Follow up: Is camel meat generally considered safe for people with celiac disease to eat?\n",
      "Intermediate answer: Generally, if camel meat is prepared in a way that avoids cross-contamination with gluten, it can be safe for people with celiac disease to eat. However, as with any food, it is important to read labels and ask questions to ensure the food is gluten-free.\n",
      "So the final answer is: It depends on how it's prepared and cooked.\n",
      "GT: Yes\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m human_opinion \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mdp[\u001b[39m'\u001b[39;49m\u001b[39mdirect_answer_result\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39manswer\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m DA correct?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m dp[\u001b[39m\"\u001b[39m\u001b[39mdirect_answer_result\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mis_right_human_opinion\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m human_opinion\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     20\u001b[0m save()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[1;32m   1192\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1195\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1196\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1235\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while i < len(results['per_question_results']):\n",
    "    dp = results['per_question_results'][i]\n",
    "    # pretty_json = json.dumps(dp[\"subquestions_result\"], indent=4)\n",
    "    # dp[\"subquestions_result\"][\"Q2_is_right_CEM\"] = compute_is_right_cover_EM(dp[\"subquestions_result\"][\"Q2_returned\"], dp[\"subquestions_result\"][\"Q2_gt\"])\n",
    "    # dp[\"subquestions_result\"][\"Q1_and_Q2_right_CEM\"] = dp[\"subquestions_result\"][\"Q2_is_right_CEM\"] and dp[\"subquestions_result\"][\"Q1_is_right_CEM\"]\n",
    "    # if dp[\"subquestions_result\"][\"Q1_and_Q2_right_CEM\"]:\n",
    "    #     count += 1\n",
    "    # Print the JSON string\n",
    "    # print(pretty_json)\n",
    "    print(\"Q: \" + dp[\"direct_answer_result\"][\"question\"])\n",
    "    print(\"DA: \" + dp[\"direct_answer_result\"][\"returned\"])\n",
    "    print(\"COT: \" + dp[\"chain_of_thought_result\"][\"returned\"])\n",
    "    print(\"SA: \" + dp[\"self_ask_result\"][\"returned\"])\n",
    "    print(\"GT: \" + dp[\"direct_answer_result\"][\"answer\"])\n",
    "    print(\"\\n\\n\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    human_opinion = input(f\"{dp['direct_answer_result']['answer']} DA correct?\")\n",
    "    dp[\"direct_answer_result\"][\"is_right_human_opinion\"] = \"t\" in human_opinion.lower()\n",
    "    save()\n",
    "\n",
    "    human_opinion = input(f\"{dp['direct_answer_result']['answer']} COT correct?\")\n",
    "    dp[\"chain_of_thought_result\"][\"is_right_human_opinion\"] = \"t\" in human_opinion.lower()\n",
    "    save()\n",
    "\n",
    "    human_opinion = input(f\"{dp['direct_answer_result']['answer']} SA correct?\")\n",
    "    dp[\"self_ask_result\"][\"is_right_human_opinion\"] = \"t\" in human_opinion.lower()\n",
    "    save()\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# results['summary']['both_subquestions_correct_CEM'] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 6: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who set the precedent of a two term limit?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"george washington\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"precedent of twoterm limit for president of united states was set by george washington who voluntarily stepped down after serving two terms in office this precedent was later enshrined in 22nd amendment to us constitution\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"When did George Washington leave office?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"march 4, 1797\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"george washington left office on march 4 1797\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who set the precedent of a two term limit?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When did George Washington leave office?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The precedent of a two-term limit for the President of the United States was set by George Washington, who voluntarily stepped down after serving two terms in office. This precedent was later enshrined in the 22nd Amendment to the U.S. Constitution.\",\n",
      "    \"Q2_returned\": \"George Washington left office on March 4, 1797.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who set the precedent of a two term limit?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"george washington\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"george washington\",\n",
      "    \"Q1_is_right_EM\": true,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"When did George Washington leave office?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"march 4, 1797\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"1797\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": true,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": true,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who set the precedent of a two term limit?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When did George Washington leave office?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"George Washington\",\n",
      "    \"Q2_returned\": \"1797\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 10: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Which company built the first steam locomotive to carry passengers on a public rail line?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"stockton and darlington railway\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"company that built first steam locomotive to carry passengers on public rail line was george stephensons company robert stephenson and company locomotive was called rocket and it was used on liverpool and manchester railway in england in 1830\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"When was Stockton and Darlington Railway founded?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"1825\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"stockton and darlington railway was founded on september 27 1825\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Which company built the first steam locomotive to carry passengers on a public rail line?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When was Stockton and Darlington Railway founded?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The company that built the first steam locomotive to carry passengers on a public rail line was George Stephenson's company, Robert Stephenson and Company. The locomotive was called the \\\"Rocket\\\" and it was used on the Liverpool and Manchester Railway in England in 1830.\",\n",
      "    \"Q2_returned\": \"Stockton and Darlington Railway was founded on September 27, 1825.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Which company built the first steam locomotive to carry passengers on a public rail line?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"stockton and darlington railway\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"george stephensons company stockton and darlington railway built first steam locomotive to carry passengers on public rail line\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"When was Stockton and Darlington Railway founded?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"1825\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"1825\",\n",
      "    \"Q2_is_right_EM\": true,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": true,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": true,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Which company built the first steam locomotive to carry passengers on a public rail line?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When was Stockton and Darlington Railway founded?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"George Stephenson's company, the Stockton and Darlington Railway, built the first steam locomotive to carry passengers on a public rail line.\",\n",
      "    \"Q2_returned\": \"1825\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 20: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who was the Filipino statesman who established the government-in-exile during the outbreak of World War II?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"manuel l. quezon\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"filipino statesman who established governmentinexile during outbreak of world war ii was manuel quezon\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"What city was Manuel L. Quezon the mayor of?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"quezon city\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"manuel l quezon was mayor of city of tayabas now known as quezon in philippines from 1905 to 1906\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the Filipino statesman who established the government-in-exile during the outbreak of World War II?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What city was Manuel L. Quezon the mayor of?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The Filipino statesman who established the government-in-exile during the outbreak of World War II was Manuel Quezon.\",\n",
      "    \"Q2_returned\": \"Manuel L. Quezon was the mayor of the city of Tayabas (now known as Quezon) in the Philippines from 1905 to 1906.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who was the Filipino statesman who established the government-in-exile during the outbreak of World War II?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"manuel l. quezon\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"manuel quezon\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"What city was Manuel L. Quezon the mayor of?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"quezon city\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"manila\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the Filipino statesman who established the government-in-exile during the outbreak of World War II?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What city was Manuel L. Quezon the mayor of?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Manuel Quezon\",\n",
      "    \"Q2_returned\": \"Manila\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 37: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"What is the current name of the fourth largest city in Germany?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"cologne\",\n",
      "        \"k\\u00f6ln\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"current name of fourth largest city in germany is cologne k\\u00f6ln in german\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"What was the original name of the fourth largest city in Germany before it changed to its current name?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"colonia agrippina\",\n",
      "        \"colonia claudia ara agrippinensium\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"original name of fourth largest city in germany was breslau before it changed to its current name wroc\\u0142aw\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the current name of the fourth largest city in Germany?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What was the original name of the fourth largest city in Germany before it changed to its current name?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The current name of the fourth largest city in Germany is Cologne (K\\u00f6ln in German).\",\n",
      "    \"Q2_returned\": \"The original name of the fourth largest city in Germany was Breslau before it changed to its current name, Wroc\\u0142aw.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"What is the current name of the fourth largest city in Germany?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"cologne\",\n",
      "        \"k\\u00f6ln\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"munich\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"What was the original name of the fourth largest city in Germany before it changed to its current name?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"colonia agrippina\",\n",
      "        \"colonia claudia ara agrippinensium\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the current name of the fourth largest city in Germany?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What was the original name of the fourth largest city in Germany before it changed to its current name?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Munich\",\n",
      "    \"Q2_returned\": \"The original name of the fourth largest city in Germany before it changed to its current name was Breslau.\\n\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 45: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"When was Apollo 11?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"july 16, 1969\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"apollo 11 was launched on july 16 1969 and landed on moon on july 20 1969\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who was in charge of the NASA on July 16, 1969?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"thomas o. paine\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"on july 16 1969 nasa administrator was thomas o paine\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": true,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": true,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When was Apollo 11?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was in charge of the NASA on July 16, 1969?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Apollo 11 was launched on July 16, 1969 and landed on the moon on July 20, 1969.\",\n",
      "    \"Q2_returned\": \"On July 16, 1969, the NASA Administrator was Thomas O. Paine.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"When was Apollo 11?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"july 16, 1969\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"july 20 1969\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who was in charge of the NASA on July 16, 1969?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"thomas o. paine\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"james e webb\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When was Apollo 11?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was in charge of the NASA on July 16, 1969?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"July 20, 1969\",\n",
      "    \"Q2_returned\": \"James E. Webb\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 71: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"What year was the oldest cat ever recorded?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"na\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"oldest cat ever recorded was named creme puff who lived to be 38 years and 3 days old she was born on august 3 1967 and passed away on august 6 2005\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"What year did the cat win the Cat of the Year award?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"na\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"im sorry but i cannot provide answer to that question as there is no specific information about which cat or which cat of year award is being referred to can you please provide more context or details about award and cat in question\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What year was the oldest cat ever recorded?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What year did the cat win the Cat of the Year award?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The oldest cat ever recorded was named Creme Puff, who lived to be 38 years and 3 days old. She was born on August 3, 1967, and passed away on August 6, 2005.\",\n",
      "    \"Q2_returned\": \"I'm sorry, but I cannot provide an answer to that question as there is no specific information about which cat or which Cat of the Year award is being referred to. Can you please provide more context or details about the award and the cat in question?\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"What year was the oldest cat ever recorded?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"na\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"2022\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"What year did the cat win the Cat of the Year award?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"na\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"sorry i cannot provide answer to this question as it is not based on any factual information or event\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What year was the oldest cat ever recorded?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What year did the cat win the Cat of the Year award?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"2022\",\n",
      "    \"Q2_returned\": \"Sorry, I cannot provide an answer to this question as it is not based on any factual information or event.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 83: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"What is the longest running video game franchise?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"space invaders\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"longest running video game franchise is believed to be super mario bros by nintendo which was first released in 1985 and has since spawned numerous sequels and spinoffs\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who produced Space Invaders?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"taito corp\",\n",
      "        \"taito\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"original space invaders video game was produced by tomohiro nishikado and released by taito corporation in 1978\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the longest running video game franchise?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who produced Space Invaders?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The longest running video game franchise is believed to be \\\"Super Mario Bros.\\\" by Nintendo, which was first released in 1985 and has since spawned numerous sequels and spin-offs.\",\n",
      "    \"Q2_returned\": \"The original Space Invaders video game was produced by Tomohiro Nishikado and released by Taito Corporation in 1978.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"What is the longest running video game franchise?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"space invaders\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"super mario bros\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who produced Space Invaders?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"taito corp\",\n",
      "        \"taito\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"tomohiro nishikado\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the longest running video game franchise?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who produced Space Invaders?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Super Mario Bros.\",\n",
      "    \"Q2_returned\": \"Tomohiro Nishikado\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 86: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who is regarded as the father of observational astronomy?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"galileo\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"ancient greek philosopher and scientist hipparchus is often regarded as father of observational astronomy he made significant contributions to field including development of first comprehensive star catalog and discovery of precession of equinoxes\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who is the father of Galileo?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"vincenzo galilei\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"father of galileo was vincenzo galilei italian musician composer and music theorist\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is regarded as the father of observational astronomy?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is the father of Galileo?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The ancient Greek philosopher and scientist, Hipparchus, is often regarded as the father of observational astronomy. He made significant contributions to the field, including the development of the first comprehensive star catalog and the discovery of the precession of the equinoxes.\",\n",
      "    \"Q2_returned\": \"The father of Galileo was Vincenzo Galilei, an Italian musician, composer, and music theorist.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who is regarded as the father of observational astronomy?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"galileo\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"galileo galilei\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who is the father of Galileo?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"vincenzo galilei\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"vincenzo galilei\",\n",
      "    \"Q2_is_right_EM\": true,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": true,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": true,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is regarded as the father of observational astronomy?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is the father of Galileo?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Galileo Galilei\",\n",
      "    \"Q2_returned\": \"Vincenzo Galilei\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 87: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who is the father of modern Hebrew?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"eliezer ben-yehuda\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"father of modern hebrew is considered to be eliezer benyehuda lexicographer and linguist who revived hebrew language in late 19th and early 20th centuries\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who is the father of Eliezer Ben-Yehuda?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"yehuda leib\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"eliezer benyehudas father was named yitzhak benzvi\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is the father of modern Hebrew?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is the father of Eliezer Ben-Yehuda?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The father of modern Hebrew is considered to be Eliezer Ben-Yehuda, a lexicographer and linguist who revived the Hebrew language in the late 19th and early 20th centuries.\",\n",
      "    \"Q2_returned\": \"Eliezer Ben-Yehuda's father was named Yitzhak Ben-Zvi.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who is the father of modern Hebrew?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"eliezer ben-yehuda\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"eliezer benyehuda\",\n",
      "    \"Q1_is_right_EM\": true,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"Who is the father of Eliezer Ben-Yehuda?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"yehuda leib\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"yehuda leib perlman\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is the father of modern Hebrew?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is the father of Eliezer Ben-Yehuda?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Eliezer Ben-Yehuda\",\n",
      "    \"Q2_returned\": \"Yehuda Leib Perlman\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 92: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who is considered the father of behaviorism?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"john watson\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"father of behaviorism is considered to be john b watson\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": false,\n",
      "    \"Q2\": \"Who was the father of John Watson?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"pickens butler watson\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"father of john watson is not clear reference as there are multiple people with that name in history and fiction could you please provide more context or information about specific john watson you are referring to\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is considered the father of behaviorism?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the father of John Watson?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The father of behaviorism is considered to be John B. Watson.\",\n",
      "    \"Q2_returned\": \"The father of John Watson is not a clear reference as there are multiple people with that name in history and fiction. Could you please provide more context or information about the specific John Watson you are referring to?\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who is considered the father of behaviorism?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"john watson\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"john b watson\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": false,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"Who was the father of John Watson?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"pickens butler watson\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"im sorry but there are several people named john watson in history and popular culture could you please provide more context or information to help me identify which john watson you are referring to\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who is considered the father of behaviorism?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the father of John Watson?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"John B. Watson\",\n",
      "    \"Q2_returned\": \"I'm sorry, but there are several people named John Watson in history and popular culture. Could you please provide more context or information to help me identify which John Watson you are referring to?\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 98: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who was the president who warned about the military industrial complex?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"dwight d. eisenhower\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"president who warned about military industrial complex was dwight d eisenhower\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"When did that Dwight D. Eisenhower die?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"march 28, 1969\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"dwight d eisenhower died on march 28 1969\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the president who warned about the military industrial complex?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When did that Dwight D. Eisenhower die?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The president who warned about the military industrial complex was Dwight D. Eisenhower.\",\n",
      "    \"Q2_returned\": \"Dwight D. Eisenhower died on March 28, 1969.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who was the president who warned about the military industrial complex?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"dwight d. eisenhower\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"dwight d eisenhower\",\n",
      "    \"Q1_is_right_EM\": true,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"When did that Dwight D. Eisenhower die?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"march 28, 1969\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"march 28 1969\",\n",
      "    \"Q2_is_right_EM\": true,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": true,\n",
      "    \"Q1_and_Q2_right_EM\": true,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": true,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the president who warned about the military industrial complex?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When did that Dwight D. Eisenhower die?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Dwight D. Eisenhower\",\n",
      "    \"Q2_returned\": \"March 28, 1969\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 100: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"What is the longest railway tunnel?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"the gotthard base tunnel\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"longest railway tunnel in world is gotthard base tunnel located in switzerland with length of 5709 kilometers 355 miles\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"What is the lowest elevation of the Gotthard Base Tunnel?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"312 m\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"lowest elevation of gotthard base tunnel is approximately 550 meters 1800 feet above sea level\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the longest railway tunnel?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the lowest elevation of the Gotthard Base Tunnel?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The longest railway tunnel in the world is the Gotthard Base Tunnel, located in Switzerland, with a length of 57.09 kilometers (35.5 miles).\",\n",
      "    \"Q2_returned\": \"The lowest elevation of the Gotthard Base Tunnel is approximately 550 meters (1,800 feet) above sea level.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"What is the longest railway tunnel?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"the gotthard base tunnel\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"longest railway tunnel is gotthard base tunnel\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"What is the lowest elevation of the Gotthard Base Tunnel?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"312 m\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"312 meters above sea level\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the longest railway tunnel?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: What is the lowest elevation of the Gotthard Base Tunnel?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The longest railway tunnel is the Gotthard Base Tunnel.\",\n",
      "    \"Q2_returned\": \"312 meters above sea level.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 114: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"When was the most recent Summer Olympics held in London?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"2012\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"most recent summer olympics held in london was in 2012\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"Which team won in women's volleyball in the 2012 Summer Olympics in London?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"brazil\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"brazilian womens volleyball team won gold medal in 2012 summer olympics in london\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": true,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": true,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When was the most recent Summer Olympics held in London?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Which team won in women's volleyball in the 2012 Summer Olympics in London?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The most recent Summer Olympics held in London was in 2012.\",\n",
      "    \"Q2_returned\": \"The Brazilian women's volleyball team won the gold medal in the 2012 Summer Olympics in London.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"When was the most recent Summer Olympics held in London?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"2012\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"most recent summer olympics held in london was in 2012\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"Which team won in women's volleyball in the 2012 Summer Olympics in London?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"brazil\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"united states team\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: When was the most recent Summer Olympics held in London?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Which team won in women's volleyball in the 2012 Summer Olympics in London?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The most recent Summer Olympics held in London was in 2012.\",\n",
      "    \"Q2_returned\": \"The United States team.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question 122: One version got self-ask correct, the other did not\n",
      "{\n",
      "    \"Q1\": \"Who was the emperor of Japan during World War I?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"emperor taish\\u014d\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"emperor of japan during world war i was emperor taish\\u014d\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"Who was the mother of Emperor Taish\\u014d?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"yanagiwara naruko\",\n",
      "        \"sawarabi no tsubone\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"mother of emperor taish\\u014d was empress dowager eish\\u014d\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the emperor of Japan during World War I?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Question: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the mother of Emperor Taish\\u014d?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"The emperor of Japan during World War I was Emperor Taish\\u014d.\",\n",
      "    \"Q2_returned\": \"The mother of Emperor Taish\\u014d was Empress Dowager Eish\\u014d.\"\n",
      "}\n",
      "{\n",
      "    \"Q1\": \"Who was the emperor of Japan during World War I?\",\n",
      "    \"Q1_gt\": [\n",
      "        \"emperor taish\\u014d\"\n",
      "    ],\n",
      "    \"Q1_pred\": \"yoshihito or emperor taish\\u014d\",\n",
      "    \"Q1_is_right_EM\": false,\n",
      "    \"Q1_is_right_CEM\": true,\n",
      "    \"Q1_is_right_GPT_opinion\": true,\n",
      "    \"Q2\": \"Who was the mother of Emperor Taish\\u014d?\",\n",
      "    \"Q2_gt\": [\n",
      "        \"yanagiwara naruko\",\n",
      "        \"sawarabi no tsubone\"\n",
      "    ],\n",
      "    \"Q2_pred\": \"empress haruko was mother of emperor taish\\u014d\",\n",
      "    \"Q2_is_right_EM\": false,\n",
      "    \"Q2_is_right_CEM\": false,\n",
      "    \"Q2_is_right_GPT_opinion\": false,\n",
      "    \"Q1_and_Q2_right_EM\": false,\n",
      "    \"Q1_and_Q2_right_CEM\": false,\n",
      "    \"Q1_and_Q2_right_GPT_opinion\": false,\n",
      "    \"Q1_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the emperor of Japan during World War I?\\nAnswer:\",\n",
      "    \"Q2_prompt\": \"Answer the question I ask in a format AS CLOSE AS POSSIBLE to the following examples. In particular, state the final answer exactly in the format indicated. DO NOT attempt a more nuanced answer, even for difficult questions, or provide more text than the following example answers for any reason. Examples: \\n\\nQuestion: How old was Theodor Haecker when he died?\\nSo the final answer is: 65 years\\nQuestion: Why did Gianni Versace die? So the final answer is: Shot.\\nQuestion: Who is the child of Dambar Shah?\\nSo the final answer is: Krishna Shah\\nQuestion: Who directed the film The Big Money?\\nSo the final answer is: John Paddy Carstairs\\n\\nQuestion: Who was the mother of Emperor Taish\\u014d?\\nAnswer:\",\n",
      "    \"Q1_returned\": \"Yoshihito (or Emperor Taish\\u014d)\",\n",
      "    \"Q2_returned\": \"Empress Haruko was the mother of Emperor Taish\\u014d.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the paths to the JSON files for the two versions\n",
    "json_file_path1 = f'results/Bamboogle_results_{model}.json'\n",
    "json_file_path2 = f'results/Bamboogle_results_{model}_prefixed.json'\n",
    "\n",
    "# Read in the data from the JSON files\n",
    "with open(json_file_path1, \"r\") as json_file:\n",
    "    data1 = json.load(json_file)\n",
    "\n",
    "with open(json_file_path2, \"r\") as json_file:\n",
    "    data2 = json.load(json_file)\n",
    "\n",
    "# Extract the per-question results from each version\n",
    "per_question_results1 = data1[\"per_question_results\"]\n",
    "per_question_results2 = data2[\"per_question_results\"]\n",
    "\n",
    "# Compare the per-question results and print out differences in correct answers\n",
    "for i in range(len(per_question_results1)):\n",
    "    subquestions_result1 = per_question_results1[i][\"subquestions_result\"]\n",
    "    direct_answer_result1 = per_question_results1[i][\"direct_answer_result\"]\n",
    "    chain_of_thought_result1 = per_question_results1[i][\"chain_of_thought_result\"]\n",
    "    self_ask_result1 = per_question_results1[i][\"self_ask_result\"]\n",
    "\n",
    "    subquestions_result2 = per_question_results2[i][\"subquestions_result\"]\n",
    "    direct_answer_result2 = per_question_results2[i][\"direct_answer_result\"]\n",
    "    chain_of_thought_result2 = per_question_results2[i][\"chain_of_thought_result\"]\n",
    "    self_ask_result2 = per_question_results2[i][\"self_ask_result\"]\n",
    "\n",
    "    # if (\n",
    "    #     (direct_answer_result1[\"is_right_EM\"] and not direct_answer_result2[\"is_right_EM\"]) or\n",
    "    #     (direct_answer_result2[\"is_right_EM\"] and not direct_answer_result1[\"is_right_EM\"])\n",
    "    # ):\n",
    "    #     print(f\"Question {i}: One version got direct answer correct, the other did not\")\n",
    "\n",
    "    # if (\n",
    "    #     (chain_of_thought_result1[\"is_right_EM\"] and not chain_of_thought_result2[\"is_right_EM\"]) or\n",
    "    #     (chain_of_thought_result2[\"is_right_EM\"] and not chain_of_thought_result1[\"is_right_EM\"])\n",
    "    # ):\n",
    "    #     print(f\"Question {i}: One version got chain of thought correct, the other did not\")\n",
    "    pretty_json_1 = json.dumps(per_question_results1[i], indent=4)\n",
    "    pretty_json_2 = json.dumps(per_question_results2[i], indent=4)\n",
    "    if (\n",
    "        (self_ask_result1[\"is_right_GPT_opinion\"] and not self_ask_result2[\"is_right_GPT_opinion\"]) \n",
    "        # or (self_ask_result2[\"is_right_EM\"] and not self_ask_result1[\"is_right_EM\"])\n",
    "    ):\n",
    "        print(f\"Question {i}: One version got self-ask correct, the other did not\")\n",
    "        print(pretty_json_1)\n",
    "        print(pretty_json_2)\n",
    "        print(\"\\n\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
