{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import urllib.request, json \n",
    "import string, re\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "\n",
    "with open('API_key.txt', 'r') as file:\n",
    "    openai.api_key = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/all_formats.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(str(s)))))\n",
    "\n",
    "def extract_answer(generated):\n",
    "    generated = generated.lower()\n",
    "    if 'final answer:' in generated:\n",
    "        after_colon = generated.split('final answer:')[-1]\n",
    "        if \"\\n\" in after_colon:\n",
    "            after_colon = after_colon.split(\"\\n\")[0]\n",
    "    elif \":\" in generated:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "        if \"\\n\" in after_colon:\n",
    "            after_colon = after_colon.split(\"\\n\")[0]\n",
    "    else:\n",
    "        after_colon = generated\n",
    "    return normalize_answer(after_colon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-04-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LM_on_expression(prompt, sample, current_model, extract_answer, max_tokens=300, start=\" =\"):\n",
    "    question = sample['Question'] + start\n",
    "    # cur_prompt = prompt_prefix + prompt + '\\n' + '\\n' + 'Question: ' + question + '\\n' + start\n",
    "    cur_prompt = prompt + ' ' + question\n",
    "\n",
    "    if current_model in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "        ans = openai.ChatCompletion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            # stop='\\n\\n',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": cur_prompt}\n",
    "            ]\n",
    "        )\n",
    "        response_text = ans['choices'][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        ans = openai.Completion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            # stop='\\n\\n',\n",
    "            prompt=cur_prompt,\n",
    "            temperature=0\n",
    "        )\n",
    "        response_text = ans['choices'][0]['text']\n",
    "    is_right = False\n",
    "    try:\n",
    "        if prompt == \"\":\n",
    "            is_right = str(sample[\"Answer\"]) in normalize_answer(response_text)\n",
    "        else:\n",
    "            cleaned_answer = extract_answer(response_text)\n",
    "            is_right = int(cleaned_answer) == sample[\"Answer\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(cur_prompt)\n",
    "        print(response_text)\n",
    "        print(e)\n",
    "    jsonres = {\n",
    "        \"question\": sample['Question'],\n",
    "        \"prompt\": cur_prompt,\n",
    "        \"answer\": sample['Answer'],\n",
    "        \"returned\": response_text,\n",
    "        \"is_right\": is_right,\n",
    "        \"is_right_CEM\": str(sample[\"Answer\"]) in normalize_answer(response_text)\n",
    "    }\n",
    "    return jsonres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_results_dict(results, prompt_results, prompt_types):\n",
    "\n",
    "    for key in prompt_types:\n",
    "        if prompt_results[key][f\"is_right\"]:\n",
    "            results[\"summary\"][f\"{key}_correct\"] += 1\n",
    "        if prompt_results[key][f\"is_right_CEM\"]:\n",
    "            results[\"summary\"][f\"{key}_CEM_correct\"] += 1\n",
    "\n",
    "    results[\"per_question_results\"].append(prompt_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# * #', '# * # * #', '# * # * # * #', '# * # * # * # * #', '# * # * # * # * # * #', '# * # * # * # * # * # * #', '# * # * # * # * # * # * # * #', '# * # * # * # * # * # * # * # * #', '# * # * # * # * # * # * # * # * # * #', '# * # * # * # * # * # * # * # * # * # * #']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'per_question_results': [],\n",
       " 'summary': {'direct_answer_correct': 0, 'unprompted_correct': 0}}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formats = [' * '.join(['#'] * (i+2)) for i in range(0, 10)]\n",
    "# formats = [\"# + # * # + #\"]\n",
    "\n",
    "prompts = {\n",
    "    \"unprompted\": \"\", \n",
    "    # \"reasoning_ok\": \"Answer the following math problem, formatting your final answer as \\\"final answer: <number>\\\". You may show your work. \", \n",
    "    \"direct_answer\": \"Answer the following math problem, final answer (number) only, NO WORDS. \"\n",
    "}\n",
    "results = {\n",
    "    f\"results_format_({format})\": {\n",
    "        \"per_question_results\": [],\n",
    "        \"summary\": {\n",
    "            **{f\"{prompt_type}_correct\": 0 for prompt_type in prompts.keys()}, **{f\"{prompt_type}_CEM_correct\": 0 for prompt_type in prompts.keys()}\n",
    "        }\n",
    "    } for format in formats\n",
    "}\n",
    "\n",
    "print(formats)\n",
    "\n",
    "{\n",
    "    \"per_question_results\": [],\n",
    "    \"summary\": {\n",
    "        \"direct_answer_correct\": 0,\n",
    "        \"unprompted_correct\": 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 421, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 416, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.9/ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.9/ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 719, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/util/retry.py\", line 400, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/six.py\", line 718, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 665, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 421, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/usr/lib/python3/dist-packages/urllib3/connectionpool.py\", line 416, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 1377, in getresponse\n",
      "    response.begin()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 320, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "  File \"/usr/lib/python3.9/http/client.py\", line 281, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.9/ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.9/ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 516, in request_raw\n",
      "    result = _thread_context.session.request(\n",
      "  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/requests/adapters.py\", line 498, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 216, in request\n",
      "    result = self.request_raw(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 529, in request_raw\n",
      "    raise error.APIConnectionError(\n",
      "openai.error.APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID aaba151531d9f3f39851140195bd0860 in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 47c7a3479ca9717f1da4b54155a7221e in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19782272d7f1102ad429612ad56593de in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Answer the following math problem, final answer (number) only, NO WORDS.  86 * 58 * 61 =\n",
      "298, 748\n",
      "invalid literal for int() with base 10: '298 748'\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "Answer the following math problem, final answer (number) only, NO WORDS.  38 * 91 * 27 =\n",
      "This mathematical operation yields 91,158.\n",
      "invalid literal for int() with base 10: 'this mathematical operation yields 91158'\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c4eaebeabcb3c886422cbfe97e8984df in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "Answer the following math problem, final answer (number) only, NO WORDS.  67 * 50 * 34 * 20 =\n",
      "Please find the solution below:\n",
      "\n",
      "23,044,000\n",
      "invalid literal for int() with base 10: ''\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "Answer the following math problem, final answer (number) only, NO WORDS.  79 * 11 * 75 * 69 * 24 * 67 =\n",
      "1,477,765,680,200, or 1.47776568 x 10^12\n",
      "invalid literal for int() with base 10: '1477765680200 or 147776568 x 1012'\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "Answer the following math problem, final answer (number) only, NO WORDS.  60 * 39 * 82 * 62 * 91 * 65 =\n",
      "6,342,014,080,000, or 6.34201408e+12 in scientific notation.\n",
      "invalid literal for int() with base 10: '6342014080000 or 634201408e12 in scientific notation'\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Answer the following math problem, final answer (number) only, NO WORDS.  13 * 2 * 11 * 44 * 66 * 44 * 24 * 40 =\n",
      "Unfortunately, it seems as though the math problem was not fully provided. Please provide the complete math problem so I can solve it for you!\n",
      "invalid literal for int() with base 10: 'unfortunately it seems as though math problem was not fully provided please provide complete math problem so i can solve it for you'\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d160adedea06a9bae89136140663062c in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/1560108208.py\", line 10, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/3439787225.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3b28061fa172335db1681f46ae4b7d55 in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for format in formats:\n",
    "    i = 0\n",
    "\n",
    "    while i < len(data[format]):\n",
    "        dp = data[format][i]\n",
    "        try:\n",
    "            prompt_results = {}\n",
    "            for key in prompts.keys():\n",
    "                prompt = prompts[key]\n",
    "                prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
    "            # Update results\n",
    "            update_results_dict(results[f\"results_format_({format})\"], prompt_results, prompts.keys())\n",
    "\n",
    "            # only run once\n",
    "            print(i)\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            # print(\"error: \", e)\n",
    "            traceback.print_exc()\n",
    "    save()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/arithmetic/multiplication_only_results_gpt-3.5-turbo.json'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file = f'results/arithmetic/multiplication_only_results_{model}.json'\n",
    "results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    with open(results_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, ensure_ascii=False, indent=4)\n",
    "save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
