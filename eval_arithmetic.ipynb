{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import urllib.request, json \n",
    "import string, re\n",
    "import random\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "\n",
    "with open('API_key.txt', 'r') as file:\n",
    "    openai.api_key = file.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/all_formats.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(str(s)))))\n",
    "\n",
    "def extract_answer(generated):\n",
    "    generated = generated.lower()\n",
    "    if 'final answer:' in generated:\n",
    "        after_colon = generated.split('final answer:')[-1]\n",
    "        if \"\\n\" in after_colon:\n",
    "            after_colon = after_colon.split(\"\\n\")[0]\n",
    "    elif \":\" in generated:\n",
    "        after_colon = generated.split(':')[-1]\n",
    "        if \"\\n\" in after_colon:\n",
    "            after_colon = after_colon.split(\"\\n\")[0]\n",
    "    else:\n",
    "        after_colon = generated\n",
    "    return normalize_answer(after_colon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-04-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LM_on_expression(prompt, sample, current_model, extract_answer, max_tokens=300):\n",
    "    question = sample['Question'] + \" =\"\n",
    "    # cur_prompt = prompt_prefix + prompt + '\\n' + '\\n' + 'Question: ' + question + '\\n' + start\n",
    "    cur_prompt = prompt + ' ' + question\n",
    "\n",
    "    if current_model in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "        ans = openai.ChatCompletion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            # stop='\\n\\n',\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": cur_prompt}\n",
    "            ]\n",
    "        )\n",
    "        response_text = ans['choices'][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        ans = openai.Completion.create(\n",
    "            model=current_model,\n",
    "            max_tokens=max_tokens,\n",
    "            # stop='\\n\\n',\n",
    "            prompt=cur_prompt,\n",
    "            temperature=0\n",
    "        )\n",
    "        response_text = ans['choices'][0]['text']\n",
    "    is_right = False\n",
    "    try:\n",
    "        cleaned_answer = extract_answer(response_text)\n",
    "        is_right = int(cleaned_answer) == sample[\"Answer\"]\n",
    "    except Exception as e:\n",
    "        print(cur_prompt)\n",
    "        print(response_text)\n",
    "        print(e)\n",
    "    jsonres = {\n",
    "        \"question\": sample['Question'],\n",
    "        \"prompt\": cur_prompt,\n",
    "        \"answer\": sample['Answer'],\n",
    "        \"returned\": response_text,\n",
    "        \"is_right\": is_right\n",
    "    }\n",
    "    return jsonres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_results_dict(results, prompt_results, prompt_types):\n",
    "\n",
    "    for key in prompt_types:\n",
    "        if prompt_results[key][f\"is_right\"]:\n",
    "            results[\"summary\"][f\"{key}_correct\"] += 1\n",
    "\n",
    "    results[\"per_question_results\"].append(prompt_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results_format_(# + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + # + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + # + # + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}, 'results_format_(# + # + # + # + # + # + # + # + # + # + #)': {'per_question_results': [], 'summary': {'reasoning_ok_correct': 0, 'direct_answer_correct': 0}}}\n",
      "['# + #', '# + # + #', '# + # + # + #', '# + # + # + # + #', '# + # + # + # + # + #', '# + # + # + # + # + # + #', '# + # + # + # + # + # + # + #', '# + # + # + # + # + # + # + # + #', '# + # + # + # + # + # + # + # + # + #', '# + # + # + # + # + # + # + # + # + # + #']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'per_question_results': [],\n",
       " 'summary': {'direct_answer_correct': 0, 'unprompted_correct': 0}}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formats = [' + '.join(['#'] * (i+2)) for i in range(0, 10)]\n",
    "# formats = [\"# + # * # + #\"]\n",
    "\n",
    "prompts = {\n",
    "    \"reasoning_ok\": \"Answer the following math problem, formatting your final answer as \\\"final answer: <number>\\\". You may show your work. \", \n",
    "    \"direct_answer\": \"Answer the following math problem, final answer (number) only, NO WORDS. \"\n",
    "}\n",
    "results = {\n",
    "    f\"results_format_({format})\": {\n",
    "        \"per_question_results\": [],\n",
    "        \"summary\": {\n",
    "            f\"{prompt_type}_correct\": 0 for prompt_type in prompts.keys()\n",
    "        }\n",
    "    } for format in formats\n",
    "}\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    "print(formats)\n",
    "\n",
    "{\n",
    "    \"per_question_results\": [],\n",
    "    \"summary\": {\n",
    "        \"direct_answer_correct\": 0,\n",
    "        \"unprompted_correct\": 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_18609/837454402.py\", line 9, in <module>\n",
      "    prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
      "  File \"/tmp/ipykernel_18609/1145792516.py\", line 7, in run_LM_on_expression\n",
      "    ans = openai.ChatCompletion.create(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/loganmilandin/.local/lib/python3.9/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a96e3f72b97a91aa3255b19c4f271f4f in your message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Answer the following math problem, formatting your final answer as \"final answer: <number>\". You may show your work.  13 + 93 =\n",
      "Sure, here's how to solve the problem:\n",
      "\n",
      "13 + 93 = (10 + 3) + (90 + 3)   // break apart the numbers by place value\n",
      "         = 10 + 90 + 3 + 3       // regroup and simplify\n",
      "         = 100 + 6               // regroup and simplify again\n",
      "         = 106                   // final answer\n",
      "\n",
      "Therefore, the final answer is 106.\n",
      "invalid literal for int() with base 10: '13 93 10 3 90 3 break apart numbers by place value 10 90 3 3 regroup and simplify 100 6 regroup and simplify again 106 final answer therefore final answer is 106'\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Answer the following math problem, formatting your final answer as \"final answer: <number>\". You may show your work.  0 + 43 =\n",
      "Final answer: 43\n",
      "\n",
      "Explanation:\n",
      "There's no need to show any work for this particular math problem, since it's a very simple addition operation between 0 and 43. The answer is simply 43.\n",
      "invalid literal for int() with base 10: 'theres no need to show any work for this particular math problem since its very simple addition operation between 0 and 43 answer is simply 43'\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Answer the following math problem, formatting your final answer as \"final answer: <number>\". You may show your work.  8 + 16 =\n",
      "Final answer: 24\n",
      "\n",
      "Work:\n",
      "To solve this problem, simply add 8 and 16 together:\n",
      "\n",
      "8 + 16 = 24\n",
      "\n",
      "Therefore, the final answer is 24.\n",
      "invalid literal for int() with base 10: '8 16 24 therefore final answer is 24'\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "for format in formats:\n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        dp = data[format][i]\n",
    "        try:\n",
    "            prompt_results = {}\n",
    "            for key in prompts.keys():\n",
    "                prompt = prompts[key]\n",
    "                prompt_results[key] = run_LM_on_expression(prompt, dp, model, extract_answer=extract_answer)\n",
    "            # Update results\n",
    "            update_results_dict(results[f\"results_format_({format})\"], prompt_results, prompt_types)\n",
    "\n",
    "            # only run once\n",
    "            print(i)\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            # print(\"error: \", e)\n",
    "            traceback.print_exc()\n",
    "save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/arithmetic/addition_only_results_gpt-3.5-turbo.json'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_file = f'results/arithmetic/addition_only_results_{model}.json'\n",
    "results_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    with open(results_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, ensure_ascii=False, indent=4)\n",
    "save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
