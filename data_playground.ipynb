{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "import string, re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8693"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load original CC dataset\n",
    "data_path = \"data/compositional_celebrities_original.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    data_with_canary = json.load(f)\n",
    "data = data_with_canary[\"data\"]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birthplace_capital', 'birthplace_rounded_lat', 'birthplace_rounded_lng', 'birthplace_tld', 'birthplace_ccn3', 'birthplace_currency', 'birthplace_currency_short', 'birthplace_currency_symbol', 'birthplace_jpn_common_name', 'birthplace_spa_common_name', 'birthplace_rus_common_name', 'birthplace_est_common_name', 'birthplace_urd_common_name', 'birthplace_callingcode', 'birthyear_nobelLiterature', 'birthdate_uspresident', 'birthyear_masterchamp']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "for dp in data:\n",
    "  if dp['category'] in categories:\n",
    "    continue\n",
    "  else:\n",
    "    categories.append(dp['category'])\n",
    "print(categories)\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit phrasing of birthplace questions\n",
    "for dp in data:\n",
    "  if \"birthplace of\" in dp[\"Question\"]:\n",
    "    dp[\"Question\"] = dp[\"Question\"].replace(\"birthplace of\", \"birth country of\")\n",
    "\n",
    "data_edited_path = \"data/compositional_celebrities_edited.json\"\n",
    "with open(data_edited_path, \"w\") as json_file:\n",
    "    json.dump({\"data\": data, \"canary\": data_with_canary[\"canary\"]}, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_prompt_phrase = {'birthplace_rounded_lng':'(rounded down) longitude of', 'birthplace_capital': \"capital of\", 'birthyear_nobelLiterature':'winner of the Nobel Prize in Literature in', 'birthplace_currency':'currency of', 'birthplace_ccn3':'ISO 3166-1 numeric code of', 'birthdate_uspresident':'President of the United States on', 'birthplace_urd_common_name':'name in Urdu of', 'birthplace_rus_common_name':'name in Russian of', 'birthplace_callingcode':'calling code of', 'birthyear_masterchamp':'champion of the Masters Tournament in', 'birthplace_currency_short':'currency abbreviation of', 'birthplace_spa_common_name':'name in Spanish of', 'birthplace_tld':'top-level domain of', 'birthplace_rounded_lat':'(rounded down) latitude of', 'birthplace_jpn_common_name':'name in Japanese of', 'birthplace_currency_symbol':'currency symbol of', 'birthplace_est_common_name':'name in Estonian of'}\n",
    "category_to_type = {'birthplace_rounded_lng':'a rounded down longitude', 'birthplace_capital': \"a capital city\", 'birthyear_nobelLiterature':'a nobel prize winner', 'birthplace_currency':'a currency', 'birthplace_ccn3':'an ISO 3166-1 numeric code', 'birthdate_uspresident':'a US president', 'birthplace_urd_common_name':'an Urdu name', 'birthplace_rus_common_name':'a Russian name', 'birthplace_callingcode':'a calling code', 'birthyear_masterchamp':'a Masters champion', 'birthplace_currency_short':'a currency abbreviation', 'birthplace_spa_common_name':'a Spanish name', 'birthplace_tld':'a top-level domain', 'birthplace_rounded_lat':'a rounded down latitude', 'birthplace_jpn_common_name':'a Japanese name', 'birthplace_currency_symbol':'a currency symbol', 'birthplace_est_common_name':'an Estonian name'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8659\n"
     ]
    }
   ],
   "source": [
    "# extract questions for use in prompts\n",
    "samples_by_category = {}\n",
    "shots = 2\n",
    "random.seed(481)\n",
    "for category in categories:\n",
    "  category_questions = [dp for dp in data if dp['category'] == category]\n",
    "  samples = random.sample(category_questions, shots)\n",
    "  for sample in samples:\n",
    "    data.remove(sample)\n",
    "  samples_by_category[category] = samples\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "random.seed(481)\n",
    "data_subset = random.sample(data, 1000)\n",
    "data_subset_path = \"data/compositional_celebrities_subset.json\"\n",
    "with open(data_subset_path, \"w\") as json_file:\n",
    "    json.dump({\"data\": data_subset, \"canary\": data_with_canary[\"canary\"]}, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a chain of thought prompt for each category\n",
    "def make_chain_of_thought_prompts():\n",
    "  prompts_by_category = dict()\n",
    "  for category in samples_by_category.keys():\n",
    "    chain_of_thought = ''\n",
    "    for idx,sample in enumerate(samples_by_category[category]):\n",
    "      if idx != 0:\n",
    "        chain_of_thought += '\\n\\n'\n",
    "      chain_of_thought += 'Question: '\n",
    "      chain_of_thought += sample['Question']\n",
    "      chain_of_thought += '\\nAnswer: '\n",
    "      if 'birthplace' in category:\n",
    "        chain_of_thought += 'The birthplace (country) of ' + sample['person'] + ' is '\n",
    "      elif 'year' in category:\n",
    "        chain_of_thought += 'The year of birth of ' + sample['person'] + ' is '\n",
    "      else:\n",
    "        chain_of_thought += 'The date of birth of ' + sample['person'] + ' is '\n",
    "      chain_of_thought+= str(sample['A1'][0]) + '. The '\n",
    "      chain_of_thought+= category_to_prompt_phrase[category] + ' ' + str(sample['A1'][0]) + (' is ' if 'birthplace' in category else ' was ')\n",
    "      chain_of_thought+= str(sample['A2'][0]) + '.\\nSo the final answer ('\n",
    "      chain_of_thought+= category_to_type[category]\n",
    "      chain_of_thought+=') is: '\n",
    "      chain_of_thought+= str(sample['Answer'][0]) +\".\"\n",
    "\n",
    "    prompts_by_category[category] = chain_of_thought\n",
    "  return prompts_by_category\n",
    "\n",
    "chain_of_thought_prompt_dict = make_chain_of_thought_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_self_ask_prompts():\n",
    "  prompts_by_category = dict()\n",
    "  for category in samples_by_category.keys():\n",
    "    self_ask = ''\n",
    "    for idx,sample in enumerate(samples_by_category[category]):\n",
    "      if idx != 0:\n",
    "        self_ask += '\\n\\n'\n",
    "\n",
    "      self_ask += 'Question: '\n",
    "      self_ask += sample['Question']\n",
    "      self_ask += '\\nAre follow up questions needed here: Yes.\\nFollow up: '\n",
    "      self_ask += sample['Q1'] + '\\nIntermediate answer: '\n",
    "      self_ask += str(sample['A1'][0]) + '.\\nFollow up: '\n",
    "      self_ask += sample['Q2'] + '\\nIntermediate answer: '\n",
    "      self_ask += str(sample['A2'][0]) + '.\\nSo the final answer is: '\n",
    "      self_ask += str(sample['Answer'][0]) +\".\"\n",
    "    prompts_by_category[category] = self_ask\n",
    "  return prompts_by_category\n",
    "\n",
    "self_ask_prompt_dict = make_self_ask_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_direct_answer_prompts():\n",
    "  prompts_by_category = dict()\n",
    "  for category in samples_by_category.keys():\n",
    "    direct_answer = ''\n",
    "    for idx,sample in enumerate(samples_by_category[category]):\n",
    "      if idx != 0:\n",
    "        direct_answer += '\\n\\n'\n",
    "\n",
    "      direct_answer += 'Question: '\n",
    "      direct_answer += sample['Question']\n",
    "      direct_answer += '\\nAnswer: '\n",
    "      direct_answer += str(sample['Answer'][0])\n",
    "    prompts_by_category[category] = direct_answer\n",
    "  return prompts_by_category\n",
    "\n",
    "direct_answer_prompt_dict = make_direct_answer_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subquestion_prompt(which_question):\n",
    "  prompts_by_category = dict()\n",
    "  for category in samples_by_category.keys():\n",
    "    subquestion_prompt = ''\n",
    "    for idx,sample in enumerate(samples_by_category[category]):\n",
    "      if idx != 0:\n",
    "        subquestion_prompt += '\\n\\n'\n",
    "\n",
    "      subquestion_prompt += 'Question: '\n",
    "      subquestion_prompt += sample[f'Q{which_question}']\n",
    "      subquestion_prompt += \"\\nAnswer: \"\n",
    "      subquestion_prompt += str(sample[f'A{which_question}'][0])\n",
    "    prompts_by_category[category] = subquestion_prompt\n",
    "  return prompts_by_category\n",
    "\n",
    "subquestion_1_prompt_dict = make_subquestion_prompt(1)\n",
    "subquestion_2_prompt_dict = make_subquestion_prompt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dictionaries into one main dictionary\n",
    "all_prompts = {\n",
    "    \"chain_of_thought_prompt_dict\": chain_of_thought_prompt_dict,\n",
    "    \"self_ask_prompt_dict\": self_ask_prompt_dict,\n",
    "    \"direct_answer_prompt_dict\": direct_answer_prompt_dict,\n",
    "    \"subquestion_1_prompt_dict\": subquestion_1_prompt_dict,\n",
    "    \"subquestion_2_prompt_dict\": subquestion_2_prompt_dict,\n",
    "}\n",
    "\n",
    "\n",
    "# Save the combined dictionary to a JSON file in the datasets folder\n",
    "with open(\"data/prompts.json\", \"w\") as json_file:\n",
    "    json.dump(all_prompts, json_file, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
